# Kubernetes SLSA L1 + L2 Pipeline with GitOps


Project Overview

This project demonstrates SLSA Build Levels 1 and 2 with GitOps-based continuous deployment. The focus is on understanding and implementing the core SLSA requirements:

-  SLSA Build L1: Scripted build with provenance generation
-  SLSA Build L2: Hosted build platform (GitHub Actions)
-  Python Application: Simple HTTP server
-  Kubernetes: Basic deployment to your K8s cluster
-  ArgoCD: GitOps continuous deployment

 SLSA Build Level 1 Requirements

From [SLSA Specification](https://slsa.dev/spec/v1.1/levels):

1. Scripted build: Build process is fully automated
2. Provenance exists: Build platform generates provenance about how the artifact was built

How we achieve this:
- GitHub Actions workflow is fully automated
- `docker/build-push-action@v6` with `provenance: true` generates SLSA provenance
- Provenance is attached to the container image in the registry

SLSA Build Level 2 Requirements

From [SLSA Specification](https://slsa.dev/spec/v1.1/levels):

1. All Build L1 requirements
2. Hosted build platform: Build service that generates provenance
3. Provenance authenticity: Provenance is generated by the build service (not user-controlled)

How we achieve this:
- GitHub Actions is the hosted build platform (not your local machine)
- `docker/build-push-action` generates provenance automatically
- Provenance includes build parameters, builder identity, and materials


 Prerequisites

-  Kubernetes cluster
-  GHCR configured in K8s
-  Self-hosted GitHub Actions runner
-  Docker on the runner
-  Git
-  ArgoCD installed in cluster (optional but recommended)

 Quick Start

 Step 1: Build Base Image First

This project uses a custom base image to avoid Docker Hub rate limits:

```bash
# Trigger the base image build workflow
gh workflow run build-base-image.yml

# Or push the base-image directory
git add base-image/
git commit -m "Add base image"
git push
```

Wait for the base image to build (check at: https://github.com/YOUR_USERNAME/K8S-SLSA/actions)

 Step 2: Update Configuration

Edit `.github/workflows/slsa-l1-l2.yml` and replace:
```yaml
IMAGE_NAME: ghcr.io/${{ github.repository_owner }}/python-slsa-web
```


 Step 3: Create Kubernetes Namespace

```bash
kubectl apply -f k8s/namespace.yaml
```

 Step 3: Create GHCR Pull Secret

```bash
kubectl create secret docker-registry ghcr-creds \
  --docker-server=ghcr.io \
  --docker-username=YOUR_GITHUB_USERNAME \
  --docker-password=YOUR_GITHUB_PAT \
  --namespace=demo
```

Step 4: Trigger CI Pipeline

```bash
git add .
git commit -m "Setup SLSA L1+L2 pipeline"
git push origin main
```

Watch the workflow at: `https://github.com/PecataP/K8S-SLSA/actions`

 Step 5: Deploy to Kubernetes

After the pipeline completes:

```bash
# Update deployment with the new image digest (from CI output)
kubectl apply -f k8s/

# Check deployment
kubectl get pods -n demo
kubectl get svc -n demo
```

Step 6: Access Your Application

```bash
# Get node IP
kubectl get nodes -o wide

# Access application
curl http://<NODE_IP>:30080

# Or use port-forward
kubectl port-forward -n demo svc/python-slsa-web 8080:80
curl http://localhost:8080
```

 What Gets Generated

When the CI pipeline runs, it generates:

1. Container Image: Pushed to GHCR
2. SLSA Provenance: Attestation manifest attached to the image
3. SBOM: Software Bill of Materials

 Viewing the Provenance

```bash
# Inspect image with provenance
docker buildx imagetools inspect ghcr.io/PecataP/python-slsa-web:latest

# You should see:
# - Image manifest
# - Provenance attestation manifest
# - SBOM attestation manifest
```

The provenance includes:
- Build parameters
- Source repository
- Commit SHA
- Builder identity (GitHub Actions)
- Materials (Dockerfile, source code)

 Understanding the CI Workflow

 Job 1: `build-and-push`

```yaml
- uses: docker/build-push-action@v6
  with:
    provenance: true  # ← This generates SLSA provenance
    sbom: true        # ← This generates SBOM
```

This single action:
-  Satisfies SLSA L1 (provenance exists)
-  Satisfies SLSA L2 (generated by hosted build service)

 Job 2: `verify-provenance`

```bash
docker buildx imagetools inspect IMAGE@DIGEST
```

This verifies:
- Provenance attestation was attached
- Image has the expected metadata

 Job 3: `summary`

Generates a nice summary showing:
- What was built
- SLSA compliance status
- Next deployment steps



Key Difference: L2 requires the build to happen on a hosted platform, and the provenance must be generated by that platform.

 Testing SLSA Compliance

 Test 1: Verify Provenance Exists

```bash
# Set your image
IMAGE="ghcr.io/PecataP/python-slsa-web:latest"

# Inspect with Docker
docker buildx imagetools inspect $IMAGE

# Look for:
# - MediaType: application/vnd.in-toto+json (provenance)
# - Subject: your image digest
```

 Test 2: Check Build Was Automated

Look at GitHub Actions logs:
1. No manual steps required
2. Build triggered automatically on push
3. All steps scripted

 Test 3: Verify Hosted Build

Check that:
- Build ran on GitHub Actions
- Provenance includes `builder.id` pointing to GitHub Actions
- Build environment is ephemeral 

 Monitoring Your Pipeline

 GitHub Actions

```bash
# View workflow runs
gh run list --workflow=slsa-l1-l2.yml

# View specific run
gh run view RUN_ID
```

 Kubernetes

```bash
# View logs
kubectl logs -n demo -l app=python-slsa-web -f

# Check status
kubectl get all -n demo

# Describe pods
kubectl describe pod -n demo
```

 Troubleshooting

 Issue: Self-hosted runner not picking up jobs

Check:
```bash
# On your runner machine
cd actions-runner
./run.sh

# Ensure it shows "Listening for Jobs"
```

 Issue: ImagePullBackOff in Kubernetes

Solution:
```bash
# Check if secret exists
kubectl get secret ghcr-creds -n demo

# Recreate if needed (use GitHub PAT with packages:read)
kubectl create secret docker-registry ghcr-creds \
  --docker-server=ghcr.io \
  --docker-username=YOUR_USERNAME \
  --docker-password=YOUR_PAT \
  -n demo
```

Issue: Provenance not showing up

Check
```bash
# Make sure provenance: true is in the workflow
grep "provenance:" .github/workflows/slsa-l1-l2.yml

# Should output: provenance: true
```

 Issue: Docker Hub Rate Limit

**Solution: We use a custom base image!**

This project eliminates Docker Hub rate limits by:
1. Building our own base image from Python Alpine (one-time)
2. Signing it with SLSA provenance
3. Pushing to GHCR (no rate limits)
4. Using it in the application build

The base image is automatically rebuilt monthly for security updates.

See [Base Image Documentation](docs/BASE-IMAGE.md) for details.

## Documentation

- [Quick Start Guide](docs/QUICK-START.md) - Get up and running in 5 minutes
- [SLSA L1/L2 Explained](docs/SLSA-L1-L2-EXPLAINED.md) - Detailed explanation of SLSA concepts
- [Base Image Strategy](docs/BASE-IMAGE.md) - Custom base image to eliminate Docker Hub dependency
- [ArgoCD GitOps Setup](docs/ARGOCD-GITOPS.md) - GitOps continuous deployment with ArgoCD

## GitOps Deployment (Optional)

If you have ArgoCD installed, you can enable automated GitOps deployment:

```bash
# Deploy ArgoCD Application
kubectl apply -f argocd/application.yaml

# ArgoCD will now automatically:
# - Watch the k8s/ folder for changes
# - Auto-sync deployments to your cluster
# - Self-heal if manual changes are made
```

See [ArgoCD GitOps documentation](docs/ARGOCD-GITOPS.md) for complete setup instructions.

